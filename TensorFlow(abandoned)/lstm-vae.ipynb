{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import codecs\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "from math import ceil\n",
    "\n",
    "import txt2xml\n",
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocab: 1667\n"
     ]
    }
   ],
   "source": [
    "with open(\"vocabulary.json\") as json_file:\n",
    "    vocab = json.load(json_file)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Size of vocab: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentence_list(file_name):\n",
    "    sentence_list = []\n",
    "    with codecs.open(file_name, \"r\", encoding=\"utf-8\") as fp:\n",
    "        for l in fp: # level(sentence)\n",
    "            sentence = \"\"\n",
    "            for word in l.split(\"  \")[:-1]: # row(word)\n",
    "                sentence += str(vocab.index(word)) + \" \"\n",
    "            sentence_list.append(sentence[:-1])\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = create_sentence_list(\"train.txt\")\n",
    "X_valid = create_sentence_list(\"valid.txt\")\n",
    "\n",
    "X_full = X_train.copy()\n",
    "X_full.extend(X_valid)\n",
    "\n",
    "# random.shuffle(X_full)\n",
    "\n",
    "# X_train = X_full[:180]\n",
    "# X_valid = X_full[180:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1189 1189 1586 99 699 801 1328 67 1326 595',\n",
       " '950 950 1417 1053 66 657 942 946 806',\n",
       " '764 753 1182 753 1323 190 497 879 1337',\n",
       " '534 981 179 1450 1045 1503 1072 1265 1621 840 934',\n",
       " '490 140 1057 1510 1542 109']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Special tokens:\n",
    "    *   `sos`: start of sentence\n",
    "    *   `eos`: end of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 30\n",
    "word_to_vec = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "\n",
    "word_to_vec.adapt([f\"sos {s} eos\" for s in X_full])\n",
    "\n",
    "word_to_vec.trainable = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Take a look at 2 vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'sos', 'eos', '1001', '1589', '962', '1568', '126', '1363']\n"
     ]
    }
   ],
   "source": [
    "print(word_to_vec.get_vocabulary()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_vec.get_vocabulary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   `encoder_inputs`, `decoder_inptus`: takes in string types for encoding/decoding.\n",
    "    *   No parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensures reproducibility on CPU\n",
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Function API of TensorFlow: apply text vectorization on input layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_ids = word_to_vec(encoder_inputs)\n",
    "decoder_input_ids = word_to_vec(decoder_inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   `encoder_embeddings`, `decoder_embeddings`: embed the vector of texts to the desired space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50\n",
    "w2v = Word2Vec([(f\"sos {s} eos\").split() for s in X_full], \n",
    "                   sg=0, vector_size=embed_size, window=2, min_count=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(len(w2v.wv.vectors), embed_size, weights=[w2v.wv.vectors], mask_zero=True)\n",
    "\n",
    "\n",
    "# encoder_embedding_layer.trainable = False\n",
    "# decoder_embedding_layer.trainable = False\n",
    "\n",
    "encoder_embeddings = embedding_layer(encoder_input_ids)\n",
    "decoder_embeddings = embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Encoder:\n",
    "    *   Takes in the embedded vector from `encoder_embeddings`.\n",
    "    *   Send it to an LSTM.\n",
    "        *   `return_state=True`: return the last hidden state in addition to the output.\n",
    "    *   LSTM outputs `encoder_outputs` and calculates a list of `encoder_state`.\n",
    "    *   `encoder_outputs` is dropped. `*encoder_state` is used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Bidirectional LSTM:\n",
    "    *   2 LSTM, 1 read from beginning to end, 1 read from end to beginning.\n",
    "    *   `encoder_state` contains 4 items:\n",
    "        *   index `0`: short-term forward\n",
    "        *   index `1`: long-term forward\n",
    "        *   index `2`: short-term backward\n",
    "        *   index `3`: long-term backward\n",
    "    *   Concatenate them for future computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_ratio = 0.3\n",
    "hidden_size = 400\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(hidden_size, return_sequences = False, return_state=True, dropout=dropout_ratio))\n",
    "\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
    "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)\n",
    "encoder_state = tf.concat(encoder_state, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Predict $\\mu$ and $\\ln(\\sigma^2)$:\n",
    "    *   2 linear layers are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 60\n",
    "latent_mean = tf.keras.layers.Dense(latent_size)(encoder_state)\n",
    "latent_ln_var = tf.keras.layers.Dense(latent_size)(encoder_state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Sampling layer:\n",
    "    *   Return a sample from $\\mathcal{N}(\\mu,\\sigma^2)$.\n",
    "    *   Same as $\\mu + \\sigma z$, where $z\\sim\\mathcal{N}(0,1)$.\n",
    "        *   Treat $z$ as constant in backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, ln_var = inputs\n",
    "        return tf.random.normal(tf.shape(ln_var)) * tf.exp(ln_var / 2) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vec = Sampling()([latent_mean, latent_ln_var])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Predict long-term and short-term memory for decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_mem = tf.keras.layers.Dense(2*hidden_size)(latent_vec)\n",
    "long_mem = tf.keras.layers.Dense(2*hidden_size)(latent_vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Decoder:\n",
    "    *   Must be (one-directional) LSTM\n",
    "    *   Same size as the encoder's bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.LSTM(2*hidden_size, return_sequences=True, dropout=dropout_ratio)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state = [short_mem, long_mem])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Output layer\n",
    "    *   Predict the likelihood of the next word to appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.keras.layers.Dense(vocab_size+1)\n",
    "Y_proba = output_layer(decoder_outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Use function API to select encoder and decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_encoder = tf.keras.Model(inputs=[encoder_inputs], outputs=[latent_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_decoder = tf.keras.Model(\n",
    "    inputs=[latent_vec, decoder_inputs], outputs=[Y_proba])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Construct full variational auto-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "variational_ae = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=[Y_proba, latent_ln_var, latent_vec])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate, clipnorm = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Training:\n",
    "    *   Use `tf.GradientTape()` to gain more low-level control over the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "batch_size = 20\n",
    "noise_rate = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(optimizer = optimizer, rec_loss = rec_loss,\n",
    "          epochs = epochs, batch_size = batch_size, noise_rate = noise_rate, \n",
    "          X_train = X_train, X_valid = X_valid):\n",
    "    # Prepare validation data\n",
    "    X_valid_enc = tf.constant(X_valid)\n",
    "    X_valid_dec = tf.constant([f\"sos {s}\" for s in X_valid])\n",
    "    Y_valid_dec = word_to_vec([f\"{s} eos\" for s in X_valid])\n",
    "\n",
    "    epoch_size = len(X_train)\n",
    "    \n",
    "    for epoch_idx in range(epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # Add noises to decoder's input\n",
    "        X_train_dec_all = X_train.copy()\n",
    "        for i, sentence in enumerate(X_train_dec_all):\n",
    "            token_list = sentence.split()\n",
    "            sentence_len = len(token_list)\n",
    "            unknown_token = word_to_vec.get_vocabulary()[1]\n",
    "            index_list = [j for j in range(min(sentence_len, max_length))]\n",
    "            noise_list = random.sample(index_list, int(sentence_len * noise_rate))\n",
    "            new_sentence = \"\"\n",
    "            for j in range(sentence_len):\n",
    "                token = token_list[j]\n",
    "                if j in noise_list:\n",
    "                    token = unknown_token\n",
    "                new_sentence += (token + \" \")\n",
    "            X_train_dec_all[i] = new_sentence.strip()\n",
    "\n",
    "        X_train_dec_all = tf.constant([f\"sos {s}\" for s in X_train_dec_all])\n",
    "\n",
    "        # batch training\n",
    "        batch_num = ceil(epoch_size / batch_size)\n",
    "        batch_idx_list = list(range(batch_num))\n",
    "        random.shuffle(batch_idx_list)\n",
    "        for batch_idx in batch_idx_list:\n",
    "            # Select batch\n",
    "            lb = batch_idx * batch_size\n",
    "            ub = min(len(X_train), (batch_idx+1) * batch_size)\n",
    "            # Set up data\n",
    "            X_train_enc = tf.constant(X_train[lb:ub])\n",
    "            X_train_dec = tf.constant(X_train_dec_all[lb:ub])\n",
    "            Y_train_dec = word_to_vec([f\"{s} eos\" for s in X_train[lb:ub]])\n",
    "            \n",
    "            # Predict and find loss\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Predict\n",
    "                Y_predict_dec, latent_mean, latent_ln_var = variational_ae([X_train_enc, X_train_dec])\n",
    "\n",
    "                reconstruct_loss = rec_loss(Y_train_dec, Y_predict_dec)\n",
    "                latent_loss = 0\n",
    "                total_loss = reconstruct_loss + latent_loss\n",
    "                avg_loss = total_loss / (ub - lb)\n",
    "                epoch_loss += total_loss\n",
    "\n",
    "                # Take gradient and backpropagate\n",
    "                grads = tape.gradient(avg_loss, variational_ae.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, variational_ae.trainable_variables))\n",
    "        \n",
    "        # Validate:\n",
    "        valid_predict, _, _ = variational_ae([X_valid_enc, X_valid_dec])\n",
    "        valid_loss = rec_loss(Y_valid_dec, valid_predict) / batch_size\n",
    "\n",
    "        # Print output\n",
    "        print(\"epoch: %3d, train loss: %.4f, valid loss: %.4f\" \n",
    "              % (epoch_idx, epoch_loss/epoch_size, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0, train loss: 0.3706, valid loss: 0.3702\n",
      "epoch:   1, train loss: 0.3684, valid loss: 0.3667\n",
      "epoch:   2, train loss: 0.3632, valid loss: 0.3677\n",
      "epoch:   3, train loss: 0.3608, valid loss: 0.3744\n",
      "epoch:   4, train loss: 0.3582, valid loss: 0.3754\n",
      "epoch:   5, train loss: 0.3541, valid loss: 0.3873\n",
      "epoch:   6, train loss: 0.3495, valid loss: 0.3891\n",
      "epoch:   7, train loss: 0.3444, valid loss: 0.4004\n",
      "epoch:   8, train loss: 0.3399, valid loss: 0.4081\n",
      "epoch:   9, train loss: 0.3366, valid loss: 0.4126\n",
      "epoch:  10, train loss: 0.3319, valid loss: 0.4149\n",
      "epoch:  11, train loss: 0.3289, valid loss: 0.4184\n",
      "epoch:  12, train loss: 0.3245, valid loss: 0.4241\n",
      "epoch:  13, train loss: 0.3234, valid loss: 0.4226\n",
      "epoch:  14, train loss: 0.3177, valid loss: 0.4267\n",
      "epoch:  15, train loss: 0.3153, valid loss: 0.4285\n",
      "epoch:  16, train loss: 0.3120, valid loss: 0.4306\n",
      "epoch:  17, train loss: 0.3100, valid loss: 0.4341\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Jupyter_Notebooks\\CISC_455\\lstm-vae.ipynb Cell 47\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Jupyter_Notebooks/CISC_455/lstm-vae.ipynb#Y100sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train()\n",
      "\u001b[1;32me:\\Jupyter_Notebooks\\CISC_455\\lstm-vae.ipynb Cell 47\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Jupyter_Notebooks/CISC_455/lstm-vae.ipynb#Y100sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m         epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m total_loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Jupyter_Notebooks/CISC_455/lstm-vae.ipynb#Y100sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m         \u001b[39m# Take gradient and backpropagate\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Jupyter_Notebooks/CISC_455/lstm-vae.ipynb#Y100sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(avg_loss, variational_ae\u001b[39m.\u001b[39;49mtrainable_variables)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Jupyter_Notebooks/CISC_455/lstm-vae.ipynb#Y100sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, variational_ae\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Jupyter_Notebooks/CISC_455/lstm-vae.ipynb#Y100sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Validate:\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1100\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1094\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1095\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1096\u001b[0m           output_gradients))\n\u001b[0;32m   1097\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1100\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1101\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1102\u001b[0m     flat_targets,\n\u001b[0;32m   1103\u001b[0m     flat_sources,\n\u001b[0;32m   1104\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1105\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1106\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1109\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1110\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1484\u001b[0m, in \u001b[0;36m_DivNoNanGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1481\u001b[0m x \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mconj(x)\n\u001b[0;32m   1482\u001b[0m y \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mconj(y)\n\u001b[0;32m   1483\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m-> 1484\u001b[0m     array_ops\u001b[39m.\u001b[39;49mreshape(\n\u001b[0;32m   1485\u001b[0m         math_ops\u001b[39m.\u001b[39;49mreduce_sum(math_ops\u001b[39m.\u001b[39;49mdiv_no_nan(grad, y), rx), sx),\n\u001b[0;32m   1486\u001b[0m     array_ops\u001b[39m.\u001b[39mreshape(\n\u001b[0;32m   1487\u001b[0m         math_ops\u001b[39m.\u001b[39mreduce_sum(\n\u001b[0;32m   1488\u001b[0m             grad \u001b[39m*\u001b[39m math_ops\u001b[39m.\u001b[39mdiv_no_nan(math_ops\u001b[39m.\u001b[39mdiv_no_nan(\u001b[39m-\u001b[39mx, y), y),  \u001b[39m# pylint: disable=invalid-unary-operand-type\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m             ry),\n\u001b[0;32m   1490\u001b[0m         sy))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:202\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmanip.reshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     67\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(tensor, shape, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-outer-name\u001b[39;00m\n\u001b[0;32m     69\u001b[0m   \u001b[39mr\u001b[39m\u001b[39m\"\"\"Reshapes a tensor.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[39m  Given `tensor`, this operation returns a new `tf.Tensor` that has the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39m    A `Tensor`. Has the same type as `tensor`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m   result \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mreshape(tensor, shape, name)\n\u001b[0;32m    203\u001b[0m   tensor_util\u001b[39m.\u001b[39mmaybe_set_static_shape(result, shape)\n\u001b[0;32m    204\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:8532\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   8530\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   8531\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 8532\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   8533\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReshape\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, tensor, shape)\n\u001b[0;32m   8534\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   8535\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_1 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/variational_decoder.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/variational_decoder.tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/variational_encoder.tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/variational_encoder.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "variational_decoder.save(\"./saved_models/variational_decoder.tf\")\n",
    "variational_encoder.save(\"./saved_models/variational_encoder.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./saved_models/vocab_dec.json', 'w') as f:\n",
    "    json.dump(word_to_vec.get_vocabulary(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(variational_decoder, word_to_vec_dec, latent_vec, max_length = 30):\n",
    "    generated = \"\"\n",
    "    vocabulary = word_to_vec_dec.get_vocabulary()\n",
    "    for idx in range(max_length):\n",
    "        decoder_inputs = tf.constant([\"sos \" + generated])\n",
    "        Y_proba = variational_decoder.predict((latent_vec, decoder_inputs))[0, idx]\n",
    "        predicted_id = np.argmax(Y_proba)\n",
    "        predicted_word = vocabulary[predicted_id]\n",
    "        if predicted_word == \"eos\":\n",
    "            break\n",
    "        generated += \" \" + predicted_word\n",
    "    return generated.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconverter = txt2xml.txt2xml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 849ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sampled_vec = tf.random.normal(shape=[1, latent_size], mean=10, stddev=1)\n",
    "    level = generate(variational_decoder, word_to_vec, sampled_vec)\n",
    "    level_txt = [vocab[int(s)] for s in level]\n",
    "    level_xml = deconverter.vector2xml(level_txt)\n",
    "    with open(f\"./level-\" + str(i) + \".xml\", \"w\") as f:\n",
    "                f.write(level_xml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4fa92b9dc5a4c9e95927d56c64a6a4c4dd484b280024c9be9da8a5e06e5cf9ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
